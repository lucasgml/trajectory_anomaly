{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "data_labels = []\n",
    "l = None\n",
    "label_index = -1\n",
    "for f1,f2,f3 in os.walk(\"Geolife Trajectories 1.3/Data/\"):\n",
    "    for p in f3:\n",
    "        if (p.startswith(\"label\")):\n",
    "            l = np.genfromtxt(os.path.join(f1,p),delimiter='\\t',skip_header=1,dtype=np.object)\n",
    "            if (l.shape == (3,)):\n",
    "                l = l.reshape( (1,3) )\n",
    "            data_labels.append(l)\n",
    "            label_index += 1\n",
    "        if(p.endswith(\".plt\") and l is not None):\n",
    "                data.append( ( label_index,np.genfromtxt(os.path.join(f1,p),delimiter=',',skip_header=6,dtype=np.object)) )\n",
    "    if (len(f2) == 0):\n",
    "        l = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns: \"Latitude\",\"Longitude\",\"Zeros\",\"Altitude\",\"DateInDays\",\"DateString\",\"TimeString\"\n",
    "#### Selecting only trajectories with more than 30 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus, walk, car, taxi, bike = [], [], [], [], []\n",
    "for label_index, entries in data:\n",
    "    for label in data_labels[label_index]:\n",
    "        start_time = label[0]\n",
    "        end_time = label[1]\n",
    "        transportation = label[2]\n",
    "        trajectory = []\n",
    "        for entry in entries:\n",
    "            entry_time = entry[5].replace(b'-',b'/') + b' ' + entry[6]\n",
    "            if (start_time <= entry_time <= end_time):\n",
    "                    trajectory.append(entry)\n",
    "        if (transportation == b'bus'):\n",
    "            bus.append(np.array(trajectory))\n",
    "        if (transportation == b'walk'):\n",
    "            walk.append(np.array(trajectory))\n",
    "        if (transportation == b'car'):\n",
    "            car.append(np.array(trajectory))\n",
    "        if (transportation == b'taxi'):\n",
    "            taxi.append(np.array(trajectory))\n",
    "        if (transportation == b'bike'):\n",
    "            bike.append(np.array(trajectory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588698 1232085 916817 3979463 915317\n"
     ]
    }
   ],
   "source": [
    "print (len(bus), len(car), len(taxi), len(walk), len(bike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3535"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_w = [d for d in walk if d.shape[0] > 30]\n",
    "len(l_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1808"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_b = [d for d in bus if d.shape[0] > 30]\n",
    "len(l_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_c = [d for d in car if d.shape[0] > 30]\n",
    "len(l_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_t = [d for d in taxi if d.shape[0] > 30]\n",
    "len(l_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1527"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_bk = [d for d in bike if d.shape[0] > 30]\n",
    "len(l_bk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating trajectory windows composed by 30 entries each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = len(l_b)\n",
    "l_b_train = l_b[:int(index * 0.8)]\n",
    "l_b_test = l_b[int(index * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = []\n",
    "for arq in l_b_train:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_train.append(arq[i*30:(i*30)+30])\n",
    "        \n",
    "sequences_test = []\n",
    "for arq in l_b_test:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_test.append(arq[i*30:(i*30)+30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'39.9365666' b'116.3036766' b'0' b'0' b'39535.3686574074' b'2008-03-28'\n",
      " b'08:50:52']\n",
      "[b'39.9365666' b'116.3036766' b'0' b'0' b'39535.3686574074' b'2008-03-28'\n",
      " b'08:50:52']\n"
     ]
    }
   ],
   "source": [
    "print(sequences_train[1][0])\n",
    "print(l_b[0][30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying if the take funcion is capturing only useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'39.9620983', b'116.3015949', b'0', b'39535.3642361111'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(sequences_train[0][0],[0,1,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarding unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_train = []\n",
    "for s in sequences_train:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful_train.append(np.array(traj))\n",
    "    \n",
    "useful_test = []\n",
    "for s in sequences_test:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful_test.append(np.array(traj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-ready dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30101"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(useful_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11798"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(useful_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_train = np.array(useful_train,dtype=np.float32)\n",
    "useful_test = np.array(useful_test,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_train[0][0]\n",
    "data_array = []\n",
    "for r1 in useful_train:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_train = np.array(data_array)\n",
    "\n",
    "useful_test[0][0]\n",
    "data_array = []\n",
    "for r1 in useful_test:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_test = np.array(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying MinMax Scaler on features to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "scaled_data_train = mm.fit_transform(data_array_train)\n",
    "scaled_data_test = mm.transform(data_array_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing preprocessed data into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8998635 , 0.8851495 , 0.30708322, 0.20280075],\n",
       "       [0.89916515, 0.8851869 , 0.30708322, 0.20280266],\n",
       "       [0.89916277, 0.88518786, 0.30708322, 0.20280266],\n",
       "       ...,\n",
       "       [0.9090991 , 0.88569593, 0.30708322, 0.49342537],\n",
       "       [0.90909886, 0.8856952 , 0.30708322, 0.49342537],\n",
       "       [0.9090996 , 0.8856952 , 0.30708322, 0.49342537]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"preprocessed_Data_train.csv\",scaled_data_train,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"preprocessed_Data_test.csv\",scaled_data_test,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_ = []\n",
    "for arq in l_w:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_.append(arq[i*30:(i*30)+30])\n",
    "        \n",
    "useful = []\n",
    "for s in sequences_:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful.append(np.array(traj))\n",
    "    \n",
    "useful = np.array(useful,dtype=np.float32)\n",
    "\n",
    "useful[0][0]\n",
    "data_array = []\n",
    "for r1 in useful:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_ = np.array(data_array)\n",
    "scaled_data_ = mm.transform(data_array_)\n",
    "np.savetxt(\"preprocessed_Data_walk.csv\",scaled_data_,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_ = []\n",
    "for arq in l_c:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_.append(arq[i*30:(i*30)+30])\n",
    "        \n",
    "useful = []\n",
    "for s in sequences_:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful.append(np.array(traj))\n",
    "    \n",
    "useful = np.array(useful,dtype=np.float32)\n",
    "\n",
    "useful[0][0]\n",
    "data_array = []\n",
    "for r1 in useful:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_ = np.array(data_array)\n",
    "scaled_data_ = mm.transform(data_array_)\n",
    "np.savetxt(\"preprocessed_Data_car.csv\",scaled_data_,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_ = []\n",
    "for arq in l_bk:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_.append(arq[i*30:(i*30)+30])\n",
    "        \n",
    "useful = []\n",
    "for s in sequences_:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful.append(np.array(traj))\n",
    "    \n",
    "useful = np.array(useful,dtype=np.float32)\n",
    "\n",
    "useful[0][0]\n",
    "data_array = []\n",
    "for r1 in useful:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_ = np.array(data_array)\n",
    "scaled_data_ = mm.transform(data_array_)\n",
    "np.savetxt(\"preprocessed_Data_bike.csv\",scaled_data_,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_ = []\n",
    "for arq in l_t:\n",
    "    for i in range(0,int(arq.shape[0]/30)):\n",
    "        sequences_.append(arq[i*30:(i*30)+30])\n",
    "        \n",
    "useful = []\n",
    "for s in sequences_:\n",
    "    traj = []\n",
    "    for t in s:\n",
    "        traj.append(np.take(t,[0,1,3,4]))\n",
    "    useful.append(np.array(traj))\n",
    "    \n",
    "useful = np.array(useful,dtype=np.float32)\n",
    "\n",
    "useful[0][0]\n",
    "data_array = []\n",
    "for r1 in useful:\n",
    "    for r2 in r1:\n",
    "        data_array.append(r2)\n",
    "data_array_ = np.array(data_array)\n",
    "scaled_data_ = mm.transform(data_array_)\n",
    "np.savetxt(\"preprocessed_Data_taxi.csv\",scaled_data_,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
